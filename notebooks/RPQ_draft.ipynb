{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73425420",
   "metadata": {},
   "source": [
    "## Neuropsych normalization\n",
    "- This is currently shared by Rebekah Wickens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab41afe3",
   "metadata": {},
   "source": [
    "- Norms <b>must</b> be standardized to be hyphenated ranges (ex: 0-64, 64-100). \n",
    "- The second number in each hyphenated range should be interpreted as \"up to but not including this number\" <p>\n",
    "    - ex: a 64 year old fits in the 64-100 range, not the 0-64 range. This is necessary for the script to derive the correct statistic for each norm/UDI pair.\n",
    "- If all norms have a 'test' column that identifies which test they are, and follow the exact same format (ex: including all criteria, even the ones they dont use) then it will be very easy to loop through and generate the master table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f086bcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Build all possible UDIs into a dataframe\n",
    "\n",
    "UDI_df = pd.DataFrame(columns=['Sex','Language','Education','Age'])\n",
    "\n",
    "index_counter = 0\n",
    "for sex in [1, 2]:\n",
    "    for language in [1, 2]:\n",
    "        for education in range(0,31):\n",
    "            for age in range(18,101):                \n",
    "                UDI_df.loc[index_counter] = {'Sex':sex,\n",
    "                                            'Language':language,\n",
    "                                            'Education':education,\n",
    "                                            'Age':age}\n",
    "                index_counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10833822",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create master identifier (as a string)\n",
    "\n",
    "UDI_df.insert(loc = 4, column = 'UDI',\n",
    "             value = \"S\"+UDI_df.Sex.astype(str) \n",
    "              + \"-L\" + UDI_df.Language.astype(str) \n",
    "              + \"-E\" + UDI_df.Education.astype(str)\n",
    "              + \"-A\" + UDI_df.Age.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c441f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import norms, split ranges into individual low/high columns as floats.\n",
    "\n",
    "df = pd.read_excel('RPQ-normes.xlsx', sheet_name='Sheet3')\n",
    "\n",
    "df['age_low'] =  df['Age'].str.split('-').str[0].astype(float)\n",
    "df['age_high']=  df['Age'].str.split('-').str[1].astype(float)\n",
    "df['edu_low'] =  df['Education'].str.split('-').str[0].astype(float)\n",
    "df['edu_high']=  df['Education'].str.split('-').str[1].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bc238d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116e606c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BinBuilder(series, addmin=False, addmax = False, minvalue = 0, maxvalue = 100):\n",
    "    # Takes a norm criteria as a pandas series and returns an ordered list of bin edges that pd.cut can work with\n",
    "    # Optionally adds min/max values\n",
    "        \n",
    "    #convert hyphens to discrete\n",
    "    split_list = list(series.str.split('-'))\n",
    "\n",
    "    #flatten to single list, convert to float\n",
    "    flat_list = list(np.concatenate(split_list).astype(np.float))\n",
    "\n",
    "    # add min/max, if applicable\n",
    "    if addmin == True:\n",
    "        flat_list.insert(0,float(minvalue))\n",
    "    if addmax == True:\n",
    "        flat_list.append(float(maxvalue))\n",
    "    \n",
    "    # remove dupes and sort\n",
    "    flat_list = list(np.sort(np.unique(flat_list)))\n",
    "    \n",
    "    # adjust bin edges such that number before hyphen always means >=\n",
    "    float_list = []\n",
    "    for i in flat_list:\n",
    "        if i == maxvalue:\n",
    "            float_list.append(i)\n",
    "        else:\n",
    "            float_list.append(i-0.001)\n",
    "    return float_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30d9479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get bins for BNT's criteria\n",
    "\n",
    "BNT_age = BinBuilder(df.Age)\n",
    "BNT_edu = BinBuilder(df.Education, addmax=True, maxvalue = 30)\n",
    "BNT_edu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab454076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply bins to the norm dataframe, concatenate them, and create a melted norms dataframe\n",
    "\n",
    "df['age_bin'] = pd.cut(x=df.age_low, bins = BNT_age)\n",
    "df['edu_bin'] = pd.cut(x=df.edu_low, bins = BNT_edu)\n",
    "df['BNT_age+edu_bin'] = df['age_bin'].astype(str) + df['edu_bin'].astype(str)\n",
    "BNT_mean = df.melt('BNT_age+edu_bin',value_vars=['Mean'], value_name ='BNT_mean')\n",
    "BNT_sd = df.melt('BNT_age+edu_bin',value_vars=['SD'], value_name = 'BNT_sd')\n",
    "\n",
    "BNT = BNT_mean.merge(BNT_sd,on='BNT_age+edu_bin',how='right')\n",
    "for col in list(BNT.columns):\n",
    "    if 'variable' in col:\n",
    "        BNT.drop(labels=[col], axis=1, inplace=True)\n",
    "BNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631989c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply bins to UDI frame, concatenate them\n",
    "\n",
    "UDI_df['age_bin'] = pd.cut(x= UDI_df['Age'], bins = BNT_age)\n",
    "UDI_df[UDI_df.Age >62]\n",
    "\n",
    "UDI_df['edu_bin'] = pd.cut(x= UDI_df['Education'], bins = BNT_edu)\n",
    "UDI_df[UDI_df.Education > 8]\n",
    "\n",
    "UDI_df['BNT_age+edu_bin'] = UDI_df['age_bin'].astype(str) + UDI_df['edu_bin'].astype(str)\n",
    "\n",
    "UDI_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b24d109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join each UDI to its relevant test statistic\n",
    "\n",
    "UDI_df = UDI_df.merge(BNT, on='BNT_age+edu_bin', how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1095dbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove 'bin' columns\n",
    "for col in list(UDI_df.columns):\n",
    "    if 'bin' in col:\n",
    "        UDI_df.drop(labels=[col], axis=1, inplace=True)\n",
    "UDI_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac55747",
   "metadata": {},
   "outputs": [],
   "source": [
    "UDI_df.to_excel('UDI_df.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48f3ec1",
   "metadata": {},
   "source": [
    "### Neuropsych norming with look-up tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "76e8a05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9eeaa19",
   "metadata": {},
   "outputs": [],
   "source": [
    "norming_config_file = \"../workflow/tabular/DSF_norming_config.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2f8a6475",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "def get_norming_config(config_file):\n",
    "    \"\"\" Read config json for a given instrument\n",
    "    \"\"\"\n",
    "    with open(config_file, 'r') as f:\n",
    "        config = json.load(f)\n",
    "    return config\n",
    "\n",
    "def read_raw_scores(instrument):\n",
    "    \"\"\" Read raw data tables for a specified instrument dict\n",
    "    \"\"\"\n",
    "    raw_data = instrument[\"raw_data\"]\n",
    "    raw_sheet = instrument[\"raw_sheet\"]    \n",
    "    df = pd.read_excel(raw_data, sheet_name=raw_sheet, engine='openpyxl',header=1).dropna(axis=0,how=\"all\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def read_baseline_scores(instrument):\n",
    "    \"\"\" Read raw data tables for a specified instrument dict\n",
    "    \"\"\"\n",
    "    raw_data = instrument[\"baseline_data\"]\n",
    "    raw_sheet = instrument[\"baseline_sheet\"]\n",
    "    df = pd.read_excel(raw_data, sheet_name=raw_sheet, engine='openpyxl').dropna(axis=0,how=\"all\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_valid_scores(df,instrument):\n",
    "    \"\"\" Check and remove out of bound or NaN scores\n",
    "    \"\"\"\n",
    "    name = instrument[\"raw_score_name\"]\n",
    "    score_range = instrument[\"range\"]\n",
    "    nan_val = int(score_range[\"n/a\"])\n",
    "    min_val = int(score_range[\"min\"])\n",
    "    max_val = int(score_range[\"max\"])\n",
    "\n",
    "    n_participants = len(df)\n",
    "    n_multiple_visits = len(df[df.index.duplicated()])\n",
    "\n",
    "    n_nan_val = len(df[df[name] == nan_val])\n",
    "    n_missing_val = len(df[df[name].isna()])\n",
    "    print(f\"n_listed_participants: {n_participants}, n_multiple_visits: {n_multiple_visits}\")\n",
    "    print(f\"n_nan_val (i.e. {nan_val}): {n_nan_val}, n_missing_val: {n_missing_val}\")\n",
    "    print(f\"Excluding ({n_missing_val}) participants with missing scores\")\n",
    "    # clean-up\n",
    "    df[name] = df[name].replace({nan_val:np.NaN})\n",
    "    df = df[df[name].notna()]\n",
    "    \n",
    "    max_available_val = np.max(df[name])\n",
    "    min_available_val = np.min(df[name])\n",
    "\n",
    "    print(f\"\\nPossible score range: ({min_val},{max_val})\")\n",
    "    print(f\"Available score range: ({min_available_val},{max_available_val})\")\n",
    "    invalid_df = df[~df[name].isin(range(min_val, max_val+1))] # (min <= score < max)\n",
    "    n_invalid_scores = len(invalid_df)\n",
    "    if n_invalid_scores > 0:\n",
    "        print(f\"n_invalid_scores: {n_invalid_scores}\")\n",
    "        print(f\"Using participants only with valid scores\")\n",
    "        df = df[df[name].isin(range(min_val, max_val+1))]\n",
    "\n",
    "    return df\n",
    "    \n",
    "def format_baseline_scores(df, strata_cols):\n",
    "    \"\"\" Format baseline score sheet so it can be filtered in pandas\n",
    "    \"\"\"\n",
    "    baselines_ranges = {}\n",
    "    for col in strata_cols: \n",
    "        # check if column has ranges separate by \"-\" delimeter\n",
    "        # Convention: upper limit is not include for demographics and scores: e.g. (0-4) implies {0,1,2,3}\n",
    "        if df[col].str.contains(\"-\").any():    \n",
    "            df[f\"{col}_min\"] = df[col].astype(str).str.split(\"-\",expand=True)[0].astype(int)\n",
    "            df[f\"{col}_max\"] = df[col].astype(str).str.split(\"-\",expand=True)[1]\n",
    "            df.loc[df[f\"{col}_max\"].isna(), f\"{col}_max\"] = df[f\"{col}_min\"].astype(int) + 1 #See Convention\n",
    "            df[f\"{col}_max\"] = df[f\"{col}_max\"].astype(int)  \n",
    "        else:\n",
    "            df[f\"{col}_min\"] = df[col].astype(int)\n",
    "            df[f\"{col}_max\"] = df[col].astype(int) + 1 #See Convention\n",
    "        \n",
    "        baselines_ranges[col] = (np.min(df[f\"{col}_min\"]), np.max(df[f\"{col}_max\"]))\n",
    "    \n",
    "    return df, baselines_ranges\n",
    "\n",
    "def get_normed_score(participant, baseline_df, raw_score_name, norming_procedure):\n",
    "    \"\"\" Filter baseline scores and return match for a given participant\n",
    "    \"\"\"\n",
    "    baseline_match_df = baseline_df.copy()\n",
    "\n",
    "    # Filter rows matching participant values\n",
    "    # Convention: upper limit is not include for demographics and scores: e.g. (0-4) implies {0,1,2,3}\n",
    "    for k,v in participant.items():\n",
    "        baseline_match_df = baseline_match_df[(baseline_match_df[f\"{k}_min\"] <= v) & \n",
    "                                    (baseline_match_df[f\"{k}_max\"] > v) ] # see convention\n",
    "\n",
    "    # Deal with zero or > 1 matches\n",
    "    if len(baseline_match_df) == 0:\n",
    "        # print(f\"No matches found for participant: {participant.name}, {dict(participant)}\")\n",
    "        normed_score = np.nan\n",
    "        note = \"Strata not found\"\n",
    "        \n",
    "    elif len(baseline_match_df) > 1:\n",
    "        print(f\"Multiple matches found for participant: {participant.name}, {dict(participant)}\")\n",
    "        print(f\"Not assigning a scaled score for {participant.name}\")\n",
    "        normed_score = np.nan\n",
    "        note = \"Multiple strata matches found\"\n",
    "\n",
    "    else:\n",
    "        # Select based on norming_procedure\n",
    "        if norming_procedure.lower() in [\"lookup_scaled_score\",\"scaled_score\"]:\n",
    "            normed_score = baseline_match_df[\"Scaled_score\"].values[0]\n",
    "            note = \"Scaled score\"\n",
    "\n",
    "        elif norming_procedure.lower() in [\"zscore\", \"z-score\", \"z_score\"]:\n",
    "            participant_dict = {\"raw_score\":baseline_match_df[raw_score_name].values[0],\n",
    "                                \"Mean\":baseline_match_df[\"Mean\"].values[0],\n",
    "                                \"SD\":baseline_match_df[\"SD\"].values[0]}\n",
    "\n",
    "            normed_score = z_score(participant_dict)\n",
    "            note = \"zscore\"\n",
    "        else:\n",
    "            print(f\"Unknown norming procedure\")\n",
    "            normed_score = np.nan\n",
    "            note = \"Unknown norming procedure\"\n",
    "\n",
    "    return normed_score, note\n",
    "\n",
    "def z_score(participant):\n",
    "    raw_score = participant[\"raw_score\"]\n",
    "    mean = participant[\"Mean\"]\n",
    "    SD = participant[\"SD\"]\n",
    "    z_score = (raw_score - mean)/SD\n",
    "    return z_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e67be5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Starting score normalization process...\n",
      "\n",
      "Instrument name: Digit Span Total (Raw score)\n",
      "Using ['Age at time of assessment'] as stratification columns\n",
      "\n",
      "------------------------------------------------------------\n",
      "***IMPORTANT: Instrument and demograhic column names should match in the raw data sheet and the baseline score sheet***\n",
      "------------------------------------------------------------\n",
      "\n",
      "n_listed_participants: 296, n_multiple_visits: 31\n",
      "n_nan_val (i.e. 999): 0, n_missing_val: 134\n",
      "Excluding (134) participants with missing scores\n",
      "\n",
      "Possible score range: (0,32)\n",
      "Available score range: (9.0,32.0)\n",
      "\n",
      "n_participants to be normalized: 162\n",
      "------------------------------------------------------------\n",
      "n_starta: 127\n",
      "starta ranges:\n",
      "{'Age at time of assessment': (30, 90), 'Digit Span Total (Raw score)': (0, 17)}\n",
      "***IMPORTANT: Any raw scores beyond these ranges will not be normalized***\n",
      "------------------------------------------------------------\n",
      "Starting score normalization based on lookup_scaled_score...\n",
      "------------------------------------------------------------\n",
      "Participants (n=95) are missing stratification matches\n",
      "------------------------------------------------------------\n",
      "Saving normed data to: /home/nikhil/projects/Parkinsons/qpn/tabular/assessments/neuropysch/digit_span_normed.xlsx\n",
      "Norming procedure completed for Digit Span Total (Raw score)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age at time of assessment</th>\n",
       "      <th>Digit Span Total (Raw score)</th>\n",
       "      <th>Digit Span Total (Normed score)</th>\n",
       "      <th>note</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Patient #</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PD00209</th>\n",
       "      <td>59.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PD00119/T1</th>\n",
       "      <td>66.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PD00820</th>\n",
       "      <td>69.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PD00262</th>\n",
       "      <td>71.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PD00523</th>\n",
       "      <td>84.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Age at time of assessment  Digit Span Total (Raw score)  \\\n",
       "Patient #                                                             \n",
       "PD00209                          59.0                           NaN   \n",
       "PD00119/T1                       66.0                           NaN   \n",
       "PD00820                          69.0                           NaN   \n",
       "PD00262                          71.0                           NaN   \n",
       "PD00523                          84.0                           NaN   \n",
       "\n",
       "            Digit Span Total (Normed score) note  \n",
       "Patient #                                         \n",
       "PD00209                                 NaN  NaN  \n",
       "PD00119/T1                              NaN  NaN  \n",
       "PD00820                                 NaN  NaN  \n",
       "PD00262                                 NaN  NaN  \n",
       "PD00523                                 NaN  NaN  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = get_norming_config(norming_config_file)\n",
    "\n",
    "instrument = config[\"instrument\"]\n",
    "data_paths = config[\"data_paths\"]\n",
    "stratification = config[\"stratification\"]\n",
    "\n",
    "norming_procedure = instrument[\"norming_procedure\"]\n",
    "\n",
    "raw_score_name = instrument[\"raw_score_name\"]\n",
    "normed_score_name = instrument[\"normed_score_name\"]\n",
    "\n",
    "participant_id_col = data_paths[\"participant_id_column\"]\n",
    "strata_cols = list(stratification.keys())\n",
    "\n",
    "print(\"-\"*80)\n",
    "print(\"Starting score normalization process...\\n\")\n",
    "print(f\"Instrument name: {raw_score_name}\")\n",
    "print(f\"Using {strata_cols} as stratification columns\\n\")\n",
    "print(\"-\"*60)\n",
    "print(\"***IMPORTANT: Instrument and demograhic column names should match in the raw data sheet and the baseline score sheet***\")\n",
    "print(\"-\"*60)\n",
    "print(\"\")\n",
    "\n",
    "raw_data_df = read_raw_scores(data_paths)\n",
    "baseline_df = read_baseline_scores(data_paths)\n",
    "\n",
    "raw_data_df = raw_data_df[[participant_id_col,raw_score_name] + strata_cols]\n",
    "raw_data_df = raw_data_df.set_index(participant_id_col)\n",
    "valid_data_df = get_valid_scores(raw_data_df,instrument)\n",
    "\n",
    "n_participants_to_normalized = len(valid_data_df)\n",
    "print(f\"\\nn_participants to be normalized: {n_participants_to_normalized}\")\n",
    "\n",
    "baseline_df, baselines_ranges = format_baseline_scores(baseline_df, strata_cols + [raw_score_name])\n",
    "n_strata = len(baseline_df)\n",
    "\n",
    "print(\"-\"*60)\n",
    "print(f\"n_starta: {n_strata}\")\n",
    "print(f\"starta ranges:\\n{baselines_ranges}\")\n",
    "print(f\"***IMPORTANT: Any raw scores beyond these ranges will not be normalized***\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "print(f\"Starting score normalization based on {norming_procedure}...\")\n",
    "normed_data_df = valid_data_df.copy()\n",
    "for idx, participant_data in normed_data_df.iterrows():\n",
    "    normed_score, note = get_normed_score(participant_data, baseline_df,raw_score_name)\n",
    "    normed_data_df.loc[idx,normed_score_name] = normed_score\n",
    "    normed_data_df.loc[idx,\"note\"] = note\n",
    "\n",
    "participants_missing_matches = list(normed_data_df[normed_data_df[normed_score_name].isna()].index)\n",
    "n_missing_matches = len(participants_missing_matches)\n",
    "\n",
    "print(\"-\"*60)\n",
    "print(f\"Participants (n={n_missing_matches}) are missing stratification matches\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "# Save data\n",
    "normed_data = data_paths[\"normed_data\"]\n",
    "normed_sheet = data_paths[\"normed_sheet\"]\n",
    "\n",
    "print(f\"Saving normed data to: {normed_data}\")\n",
    "save_df = pd.merge(raw_data_df[strata_cols + [raw_score_name]], \n",
    "                    normed_data_df[strata_cols + [normed_score_name, \"note\"]], \n",
    "                  on=[participant_id_col] + strata_cols, how=\"left\")\n",
    "\n",
    "save_df.to_excel(normed_data, sheet_name=normed_sheet)\n",
    "print(f\"Norming procedure completed for {raw_score_name}\")\n",
    "print(\"-\"*80)\n",
    "save_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
